{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Next, is our dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data. In this case I am going to use data from the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset. This dataset has full user reviews of cars and hotels. I have specifically concatenated all of the hotel reviews into one big file which is about 97MB compressed and 229MB uncompressed. We will use the compressed file for this tutorial. Each line in this file represents a hotel review. You can download the OpinRank Word2Vec dataset here.\n",
    "\n",
    "To avoid confusion, while gensim’s word2vec tutorial says that you need to pass it a sequence of sentences as its input, you can always pass it a whole review as a sentence (i.e. a much larger size of text), and it should not make much of a difference. \n",
    "\n",
    "Now, let's take a closer look at this data below by printing the first line. You can see that this is a pretty hefty review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into a list\n",
    "Now that we've had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below, that I am directly reading the \n",
    "compressed file. I'm also doing a mild pre-processing of the reviews using `gensim.utils.simple_preprocess (line)`. This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official [Gensim documentation site](https://radimrehurek.com/gensim/utils.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 09:41:36,456 : INFO : reading file reviews_data.txt.gz...this may take a while\n",
      "2022-02-16 09:41:36,458 : INFO : read 0 reviews\n",
      "2022-02-16 09:41:37,946 : INFO : read 10000 reviews\n",
      "2022-02-16 09:41:39,444 : INFO : read 20000 reviews\n",
      "2022-02-16 09:41:41,147 : INFO : read 30000 reviews\n",
      "2022-02-16 09:41:42,742 : INFO : read 40000 reviews\n",
      "2022-02-16 09:41:44,744 : INFO : read 50000 reviews\n",
      "2022-02-16 09:41:46,450 : INFO : read 60000 reviews\n",
      "2022-02-16 09:41:47,916 : INFO : read 70000 reviews\n",
      "2022-02-16 09:41:49,236 : INFO : read 80000 reviews\n",
      "2022-02-16 09:41:50,633 : INFO : read 90000 reviews\n",
      "2022-02-16 09:41:51,988 : INFO : read 100000 reviews\n",
      "2022-02-16 09:41:53,323 : INFO : read 110000 reviews\n",
      "2022-02-16 09:41:54,688 : INFO : read 120000 reviews\n",
      "2022-02-16 09:41:56,060 : INFO : read 130000 reviews\n",
      "2022-02-16 09:41:58,081 : INFO : read 140000 reviews\n",
      "2022-02-16 09:41:59,434 : INFO : read 150000 reviews\n",
      "2022-02-16 09:42:00,823 : INFO : read 160000 reviews\n",
      "2022-02-16 09:42:02,180 : INFO : read 170000 reviews\n",
      "2022-02-16 09:42:03,647 : INFO : read 180000 reviews\n",
      "2022-02-16 09:42:05,051 : INFO : read 190000 reviews\n",
      "2022-02-16 09:42:06,571 : INFO : read 200000 reviews\n",
      "2022-02-16 09:42:08,030 : INFO : read 210000 reviews\n",
      "2022-02-16 09:42:09,502 : INFO : read 220000 reviews\n",
      "2022-02-16 09:42:11,689 : INFO : read 230000 reviews\n",
      "2022-02-16 09:42:13,100 : INFO : read 240000 reviews\n",
      "2022-02-16 09:42:14,489 : INFO : read 250000 reviews\n",
      "2022-02-16 09:42:15,237 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step (the `documents`). So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.\n",
    "\n",
    "After building the vocabulary, we just need to call `train(...)` to start training the Word2Vec model. Training on the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset takes about 10 minutes so please be patient while running your code on this dataset.\n",
    "\n",
    "Behind the scenes we are actually training a simple neural network with a single hidden layer. But, we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 09:59:57,599 : INFO : collecting all words and their counts\n",
      "2022-02-16 09:59:57,601 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-02-16 09:59:57,816 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2022-02-16 09:59:58,038 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2022-02-16 09:59:58,295 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2022-02-16 09:59:58,537 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2022-02-16 09:59:58,803 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2022-02-16 09:59:59,070 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2022-02-16 09:59:59,288 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2022-02-16 09:59:59,488 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2022-02-16 09:59:59,699 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2022-02-16 09:59:59,902 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2022-02-16 10:00:00,104 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2022-02-16 10:00:00,307 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2022-02-16 10:00:00,516 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2022-02-16 10:00:00,740 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2022-02-16 10:00:00,948 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2022-02-16 10:00:01,164 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2022-02-16 10:00:01,372 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2022-02-16 10:00:01,595 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2022-02-16 10:00:01,808 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2022-02-16 10:00:02,040 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2022-02-16 10:00:02,267 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2022-02-16 10:00:02,495 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2022-02-16 10:00:02,700 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2022-02-16 10:00:02,913 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2022-02-16 10:00:03,134 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2022-02-16 10:00:03,254 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2022-02-16 10:00:03,255 : INFO : Creating a fresh vocabulary\n",
      "2022-02-16 10:00:03,497 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 70537 unique words (47.00617757015574%% of original 150059, drops 79522)', 'datetime': '2022-02-16T10:00:03.497263', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2022-02-16 10:00:03,498 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 41439836 word corpus (99.80847006353036%% of original 41519358, drops 79522)', 'datetime': '2022-02-16T10:00:03.498260', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2022-02-16 10:00:03,883 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2022-02-16 10:00:03,888 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2022-02-16 10:00:03,889 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30349251.36700416 word corpus (73.2%% of prior 41439836)', 'datetime': '2022-02-16T10:00:03.889757', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2022-02-16 10:00:04,538 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2022-02-16 10:00:04,539 : INFO : resetting layer weights\n",
      "2022-02-16 10:00:04,584 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-02-16T10:00:04.584335', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'build_vocab'}\n",
      "2022-02-16 10:00:04,585 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-02-16T10:00:04.585315', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2022-02-16 10:00:05,598 : INFO : EPOCH 1 - PROGRESS: at 6.01% examples, 1845619 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:06,601 : INFO : EPOCH 1 - PROGRESS: at 11.36% examples, 1829685 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:07,602 : INFO : EPOCH 1 - PROGRESS: at 16.24% examples, 1793423 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:08,606 : INFO : EPOCH 1 - PROGRESS: at 20.53% examples, 1751116 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:09,607 : INFO : EPOCH 1 - PROGRESS: at 25.05% examples, 1715371 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:10,609 : INFO : EPOCH 1 - PROGRESS: at 31.17% examples, 1708018 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:11,610 : INFO : EPOCH 1 - PROGRESS: at 36.82% examples, 1695779 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:12,613 : INFO : EPOCH 1 - PROGRESS: at 42.55% examples, 1682892 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:13,615 : INFO : EPOCH 1 - PROGRESS: at 48.12% examples, 1670187 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:14,617 : INFO : EPOCH 1 - PROGRESS: at 53.34% examples, 1657497 words/s, in_qsize 20, out_qsize 1\n",
      "2022-02-16 10:00:15,621 : INFO : EPOCH 1 - PROGRESS: at 58.76% examples, 1647686 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:16,622 : INFO : EPOCH 1 - PROGRESS: at 64.11% examples, 1635531 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:17,633 : INFO : EPOCH 1 - PROGRESS: at 69.32% examples, 1628349 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:18,638 : INFO : EPOCH 1 - PROGRESS: at 74.54% examples, 1622089 words/s, in_qsize 19, out_qsize 1\n",
      "2022-02-16 10:00:19,651 : INFO : EPOCH 1 - PROGRESS: at 79.67% examples, 1620077 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:20,655 : INFO : EPOCH 1 - PROGRESS: at 84.87% examples, 1618693 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:21,658 : INFO : EPOCH 1 - PROGRESS: at 90.32% examples, 1614037 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:22,660 : INFO : EPOCH 1 - PROGRESS: at 95.82% examples, 1613268 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:23,344 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:00:23,348 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:00:23,351 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:00:23,356 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:00:23,359 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:00:23,362 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:00:23,366 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:00:23,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:00:23,372 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:00:23,376 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:00:23,377 : INFO : EPOCH - 1 : training on 41519358 raw words (30352931 effective words) took 18.8s, 1615947 effective words/s\n",
      "2022-02-16 10:00:24,386 : INFO : EPOCH 2 - PROGRESS: at 5.19% examples, 1599456 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:25,391 : INFO : EPOCH 2 - PROGRESS: at 10.32% examples, 1647436 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:26,393 : INFO : EPOCH 2 - PROGRESS: at 15.12% examples, 1667633 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:27,397 : INFO : EPOCH 2 - PROGRESS: at 19.58% examples, 1655924 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:28,398 : INFO : EPOCH 2 - PROGRESS: at 23.91% examples, 1639987 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:29,399 : INFO : EPOCH 2 - PROGRESS: at 29.43% examples, 1628464 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:30,402 : INFO : EPOCH 2 - PROGRESS: at 35.06% examples, 1625243 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:31,405 : INFO : EPOCH 2 - PROGRESS: at 40.89% examples, 1626926 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:32,405 : INFO : EPOCH 2 - PROGRESS: at 46.89% examples, 1630159 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:33,411 : INFO : EPOCH 2 - PROGRESS: at 52.31% examples, 1623824 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:34,415 : INFO : EPOCH 2 - PROGRESS: at 58.10% examples, 1629956 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:35,424 : INFO : EPOCH 2 - PROGRESS: at 64.08% examples, 1633325 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:36,425 : INFO : EPOCH 2 - PROGRESS: at 69.49% examples, 1632396 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:37,427 : INFO : EPOCH 2 - PROGRESS: at 75.10% examples, 1635001 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:38,428 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 1637802 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:39,434 : INFO : EPOCH 2 - PROGRESS: at 85.96% examples, 1639989 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:40,438 : INFO : EPOCH 2 - PROGRESS: at 91.80% examples, 1640049 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:41,440 : INFO : EPOCH 2 - PROGRESS: at 97.40% examples, 1639273 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:41,849 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:00:41,853 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:00:41,854 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:00:41,859 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:00:41,864 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:00:41,865 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:00:41,867 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:00:41,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:00:41,873 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:00:41,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:00:41,877 : INFO : EPOCH - 2 : training on 41519358 raw words (30351172 effective words) took 18.5s, 1641268 effective words/s\n",
      "2022-02-16 10:00:42,894 : INFO : EPOCH 3 - PROGRESS: at 5.40% examples, 1653072 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:43,900 : INFO : EPOCH 3 - PROGRESS: at 10.28% examples, 1634634 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:44,902 : INFO : EPOCH 3 - PROGRESS: at 14.99% examples, 1647423 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:45,903 : INFO : EPOCH 3 - PROGRESS: at 19.46% examples, 1645158 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:46,909 : INFO : EPOCH 3 - PROGRESS: at 23.80% examples, 1627174 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:47,920 : INFO : EPOCH 3 - PROGRESS: at 29.43% examples, 1623150 words/s, in_qsize 20, out_qsize 1\n",
      "2022-02-16 10:00:48,922 : INFO : EPOCH 3 - PROGRESS: at 35.14% examples, 1624234 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:00:49,923 : INFO : EPOCH 3 - PROGRESS: at 40.89% examples, 1623485 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:50,931 : INFO : EPOCH 3 - PROGRESS: at 46.85% examples, 1624250 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:51,933 : INFO : EPOCH 3 - PROGRESS: at 52.47% examples, 1624765 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:52,935 : INFO : EPOCH 3 - PROGRESS: at 58.17% examples, 1629056 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:53,937 : INFO : EPOCH 3 - PROGRESS: at 64.05% examples, 1631059 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:54,939 : INFO : EPOCH 3 - PROGRESS: at 69.66% examples, 1634817 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:55,941 : INFO : EPOCH 3 - PROGRESS: at 75.16% examples, 1635189 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:56,943 : INFO : EPOCH 3 - PROGRESS: at 80.56% examples, 1638673 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:57,945 : INFO : EPOCH 3 - PROGRESS: at 85.94% examples, 1638533 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:58,947 : INFO : EPOCH 3 - PROGRESS: at 91.91% examples, 1641014 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:00:59,950 : INFO : EPOCH 3 - PROGRESS: at 97.75% examples, 1644818 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:00,289 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:01:00,292 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:01:00,295 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:01:00,297 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:01:00,299 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:01:00,301 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:01:00,310 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:01:00,311 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:01:00,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:01:00,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:01:00,318 : INFO : EPOCH - 3 : training on 41519358 raw words (30351399 effective words) took 18.4s, 1646680 effective words/s\n",
      "2022-02-16 10:01:01,326 : INFO : EPOCH 4 - PROGRESS: at 5.07% examples, 1566494 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:02,327 : INFO : EPOCH 4 - PROGRESS: at 10.13% examples, 1612417 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:03,335 : INFO : EPOCH 4 - PROGRESS: at 14.72% examples, 1617459 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:04,336 : INFO : EPOCH 4 - PROGRESS: at 19.22% examples, 1622751 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:05,342 : INFO : EPOCH 4 - PROGRESS: at 23.80% examples, 1629202 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:06,347 : INFO : EPOCH 4 - PROGRESS: at 29.46% examples, 1627812 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:07,351 : INFO : EPOCH 4 - PROGRESS: at 35.29% examples, 1632635 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:08,354 : INFO : EPOCH 4 - PROGRESS: at 41.33% examples, 1637736 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:09,355 : INFO : EPOCH 4 - PROGRESS: at 47.25% examples, 1640513 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:10,360 : INFO : EPOCH 4 - PROGRESS: at 52.91% examples, 1641967 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:11,361 : INFO : EPOCH 4 - PROGRESS: at 58.68% examples, 1644151 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:12,366 : INFO : EPOCH 4 - PROGRESS: at 64.81% examples, 1649240 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:13,368 : INFO : EPOCH 4 - PROGRESS: at 70.27% examples, 1651281 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:14,370 : INFO : EPOCH 4 - PROGRESS: at 75.91% examples, 1652539 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:15,374 : INFO : EPOCH 4 - PROGRESS: at 81.23% examples, 1653227 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:16,377 : INFO : EPOCH 4 - PROGRESS: at 86.73% examples, 1653054 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:17,378 : INFO : EPOCH 4 - PROGRESS: at 92.62% examples, 1653918 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:18,378 : INFO : EPOCH 4 - PROGRESS: at 98.37% examples, 1655691 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:18,614 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:01:18,619 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:01:18,619 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:01:18,621 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:01:18,626 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:01:18,628 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:01:18,634 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:01:18,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:01:18,638 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:01:18,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:01:18,642 : INFO : EPOCH - 4 : training on 41519358 raw words (30347591 effective words) took 18.3s, 1656827 effective words/s\n",
      "2022-02-16 10:01:19,656 : INFO : EPOCH 5 - PROGRESS: at 5.10% examples, 1565469 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:20,663 : INFO : EPOCH 5 - PROGRESS: at 10.07% examples, 1591971 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:21,668 : INFO : EPOCH 5 - PROGRESS: at 14.75% examples, 1617284 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:22,670 : INFO : EPOCH 5 - PROGRESS: at 19.32% examples, 1629428 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:23,671 : INFO : EPOCH 5 - PROGRESS: at 23.85% examples, 1631835 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:24,676 : INFO : EPOCH 5 - PROGRESS: at 29.53% examples, 1630153 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:25,677 : INFO : EPOCH 5 - PROGRESS: at 35.25% examples, 1630164 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:26,684 : INFO : EPOCH 5 - PROGRESS: at 41.27% examples, 1634904 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:27,687 : INFO : EPOCH 5 - PROGRESS: at 47.25% examples, 1639182 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:28,687 : INFO : EPOCH 5 - PROGRESS: at 52.76% examples, 1636344 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:29,694 : INFO : EPOCH 5 - PROGRESS: at 58.54% examples, 1639593 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:30,698 : INFO : EPOCH 5 - PROGRESS: at 64.55% examples, 1642335 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:31,699 : INFO : EPOCH 5 - PROGRESS: at 69.87% examples, 1639620 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:32,705 : INFO : EPOCH 5 - PROGRESS: at 75.40% examples, 1639781 words/s, in_qsize 20, out_qsize 1\n",
      "2022-02-16 10:01:33,708 : INFO : EPOCH 5 - PROGRESS: at 80.49% examples, 1637140 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:34,712 : INFO : EPOCH 5 - PROGRESS: at 85.94% examples, 1638208 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:35,714 : INFO : EPOCH 5 - PROGRESS: at 91.91% examples, 1640680 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:36,725 : INFO : EPOCH 5 - PROGRESS: at 97.66% examples, 1642571 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:37,077 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:01:37,083 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:01:37,084 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:01:37,086 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:01:37,092 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:01:37,095 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:01:37,097 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:01:37,101 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:01:37,102 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:01:37,106 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:01:37,106 : INFO : EPOCH - 5 : training on 41519358 raw words (30350361 effective words) took 18.5s, 1644452 effective words/s\n",
      "2022-02-16 10:01:37,107 : INFO : Word2Vec lifecycle event {'msg': 'training on 207596790 raw words (151753454 effective words) took 92.5s, 1640191 effective words/s', 'datetime': '2022-02-16T10:01:37.107841', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2022-02-16 10:01:37,108 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=70537, vector_size=150, alpha=0.025)', 'datetime': '2022-02-16T10:01:37.108794', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "2022-02-16 10:01:37,109 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2022-02-16 10:01:37,110 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 70537 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-02-16T10:01:37.110440', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "2022-02-16 10:01:38,121 : INFO : EPOCH 1 - PROGRESS: at 5.07% examples, 1561419 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:39,128 : INFO : EPOCH 1 - PROGRESS: at 10.02% examples, 1587566 words/s, in_qsize 20, out_qsize 1\n",
      "2022-02-16 10:01:40,130 : INFO : EPOCH 1 - PROGRESS: at 14.58% examples, 1601112 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:41,133 : INFO : EPOCH 1 - PROGRESS: at 19.15% examples, 1613603 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:42,134 : INFO : EPOCH 1 - PROGRESS: at 23.71% examples, 1621702 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:43,135 : INFO : EPOCH 1 - PROGRESS: at 29.50% examples, 1631187 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:44,142 : INFO : EPOCH 1 - PROGRESS: at 35.48% examples, 1640153 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:45,142 : INFO : EPOCH 1 - PROGRESS: at 41.50% examples, 1644052 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:46,145 : INFO : EPOCH 1 - PROGRESS: at 47.37% examples, 1644897 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:47,147 : INFO : EPOCH 1 - PROGRESS: at 53.01% examples, 1646247 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:48,153 : INFO : EPOCH 1 - PROGRESS: at 58.73% examples, 1645451 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:49,160 : INFO : EPOCH 1 - PROGRESS: at 64.61% examples, 1644366 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:50,162 : INFO : EPOCH 1 - PROGRESS: at 69.97% examples, 1643562 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:51,165 : INFO : EPOCH 1 - PROGRESS: at 75.40% examples, 1640715 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:52,169 : INFO : EPOCH 1 - PROGRESS: at 80.66% examples, 1641770 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:53,170 : INFO : EPOCH 1 - PROGRESS: at 86.19% examples, 1644153 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:54,172 : INFO : EPOCH 1 - PROGRESS: at 92.15% examples, 1645482 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:55,174 : INFO : EPOCH 1 - PROGRESS: at 97.87% examples, 1647107 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:55,488 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:01:55,493 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:01:55,499 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:01:55,500 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:01:55,504 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:01:55,505 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:01:55,506 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:01:55,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:01:55,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:01:55,515 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:01:55,516 : INFO : EPOCH - 1 : training on 41519358 raw words (30350985 effective words) took 18.4s, 1649722 effective words/s\n",
      "2022-02-16 10:01:56,531 : INFO : EPOCH 2 - PROGRESS: at 5.13% examples, 1567382 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:01:57,538 : INFO : EPOCH 2 - PROGRESS: at 10.04% examples, 1587021 words/s, in_qsize 19, out_qsize 1\n",
      "2022-02-16 10:01:58,540 : INFO : EPOCH 2 - PROGRESS: at 14.38% examples, 1577308 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:01:59,541 : INFO : EPOCH 2 - PROGRESS: at 18.91% examples, 1587876 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:00,541 : INFO : EPOCH 2 - PROGRESS: at 23.31% examples, 1590052 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:01,547 : INFO : EPOCH 2 - PROGRESS: at 28.56% examples, 1585290 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:02,552 : INFO : EPOCH 2 - PROGRESS: at 34.07% examples, 1581387 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:03,552 : INFO : EPOCH 2 - PROGRESS: at 39.85% examples, 1589072 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:04,555 : INFO : EPOCH 2 - PROGRESS: at 46.07% examples, 1599296 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:05,559 : INFO : EPOCH 2 - PROGRESS: at 51.83% examples, 1607035 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:06,563 : INFO : EPOCH 2 - PROGRESS: at 57.41% examples, 1609456 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:07,563 : INFO : EPOCH 2 - PROGRESS: at 63.11% examples, 1613338 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:08,567 : INFO : EPOCH 2 - PROGRESS: at 68.77% examples, 1614190 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:09,574 : INFO : EPOCH 2 - PROGRESS: at 74.45% examples, 1619015 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:10,579 : INFO : EPOCH 2 - PROGRESS: at 79.82% examples, 1623226 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:11,579 : INFO : EPOCH 2 - PROGRESS: at 85.27% examples, 1626532 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:12,587 : INFO : EPOCH 2 - PROGRESS: at 91.34% examples, 1630634 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:13,588 : INFO : EPOCH 2 - PROGRESS: at 97.07% examples, 1633320 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:14,038 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:02:14,043 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:02:14,047 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:02:14,050 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:02:14,056 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:02:14,057 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:02:14,058 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:02:14,064 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:02:14,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:02:14,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:02:14,068 : INFO : EPOCH - 2 : training on 41519358 raw words (30345989 effective words) took 18.5s, 1636338 effective words/s\n",
      "2022-02-16 10:02:15,086 : INFO : EPOCH 3 - PROGRESS: at 5.19% examples, 1586828 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:16,086 : INFO : EPOCH 3 - PROGRESS: at 9.99% examples, 1583260 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:17,092 : INFO : EPOCH 3 - PROGRESS: at 14.52% examples, 1591594 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:18,094 : INFO : EPOCH 3 - PROGRESS: at 19.07% examples, 1603706 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:19,095 : INFO : EPOCH 3 - PROGRESS: at 23.51% examples, 1605149 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:20,097 : INFO : EPOCH 3 - PROGRESS: at 28.99% examples, 1605099 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:21,104 : INFO : EPOCH 3 - PROGRESS: at 34.62% examples, 1603264 words/s, in_qsize 16, out_qsize 3\n",
      "2022-02-16 10:02:22,104 : INFO : EPOCH 3 - PROGRESS: at 40.39% examples, 1607183 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:23,106 : INFO : EPOCH 3 - PROGRESS: at 46.40% examples, 1611791 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:24,108 : INFO : EPOCH 3 - PROGRESS: at 52.20% examples, 1619402 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:25,111 : INFO : EPOCH 3 - PROGRESS: at 57.81% examples, 1621426 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:26,113 : INFO : EPOCH 3 - PROGRESS: at 63.73% examples, 1626644 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:27,113 : INFO : EPOCH 3 - PROGRESS: at 69.35% examples, 1629035 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:28,115 : INFO : EPOCH 3 - PROGRESS: at 74.89% examples, 1630309 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:29,118 : INFO : EPOCH 3 - PROGRESS: at 80.14% examples, 1631784 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:30,118 : INFO : EPOCH 3 - PROGRESS: at 85.35% examples, 1629969 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:31,123 : INFO : EPOCH 3 - PROGRESS: at 91.26% examples, 1631291 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:32,126 : INFO : EPOCH 3 - PROGRESS: at 97.02% examples, 1634207 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:32,589 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:02:32,595 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:02:32,599 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:02:32,602 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:02:32,609 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:02:32,611 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:02:32,614 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:02:32,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:02:32,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:02:32,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:02:32,621 : INFO : EPOCH - 3 : training on 41519358 raw words (30350982 effective words) took 18.5s, 1636667 effective words/s\n",
      "2022-02-16 10:02:33,629 : INFO : EPOCH 4 - PROGRESS: at 5.01% examples, 1544616 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:34,635 : INFO : EPOCH 4 - PROGRESS: at 9.89% examples, 1568416 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:35,641 : INFO : EPOCH 4 - PROGRESS: at 14.48% examples, 1589159 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:36,642 : INFO : EPOCH 4 - PROGRESS: at 19.15% examples, 1613954 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:37,643 : INFO : EPOCH 4 - PROGRESS: at 23.71% examples, 1622399 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:38,644 : INFO : EPOCH 4 - PROGRESS: at 29.34% examples, 1623367 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:39,644 : INFO : EPOCH 4 - PROGRESS: at 35.04% examples, 1624533 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:40,646 : INFO : EPOCH 4 - PROGRESS: at 40.76% examples, 1622601 words/s, in_qsize 18, out_qsize 1\n",
      "2022-02-16 10:02:41,646 : INFO : EPOCH 4 - PROGRESS: at 46.85% examples, 1628890 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:42,653 : INFO : EPOCH 4 - PROGRESS: at 52.64% examples, 1634050 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:43,659 : INFO : EPOCH 4 - PROGRESS: at 58.30% examples, 1635010 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:44,660 : INFO : EPOCH 4 - PROGRESS: at 64.22% examples, 1637226 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:45,663 : INFO : EPOCH 4 - PROGRESS: at 69.70% examples, 1638001 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:46,664 : INFO : EPOCH 4 - PROGRESS: at 75.40% examples, 1641954 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:47,668 : INFO : EPOCH 4 - PROGRESS: at 80.78% examples, 1645333 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:48,668 : INFO : EPOCH 4 - PROGRESS: at 86.39% examples, 1648554 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:49,672 : INFO : EPOCH 4 - PROGRESS: at 92.49% examples, 1652280 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:50,675 : INFO : EPOCH 4 - PROGRESS: at 98.30% examples, 1655176 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:50,916 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:02:50,921 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:02:50,925 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:02:50,930 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:02:50,933 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:02:50,935 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:02:50,936 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:02:50,938 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:02:50,943 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:02:50,945 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:02:50,946 : INFO : EPOCH - 4 : training on 41519358 raw words (30349629 effective words) took 18.3s, 1656881 effective words/s\n",
      "2022-02-16 10:02:51,955 : INFO : EPOCH 5 - PROGRESS: at 5.47% examples, 1686240 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:52,958 : INFO : EPOCH 5 - PROGRESS: at 10.53% examples, 1683039 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:02:53,963 : INFO : EPOCH 5 - PROGRESS: at 15.16% examples, 1673027 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:54,968 : INFO : EPOCH 5 - PROGRESS: at 19.52% examples, 1651897 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:55,968 : INFO : EPOCH 5 - PROGRESS: at 23.89% examples, 1638093 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:56,970 : INFO : EPOCH 5 - PROGRESS: at 29.59% examples, 1634961 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:57,970 : INFO : EPOCH 5 - PROGRESS: at 35.33% examples, 1636699 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:58,972 : INFO : EPOCH 5 - PROGRESS: at 41.47% examples, 1644459 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:02:59,975 : INFO : EPOCH 5 - PROGRESS: at 47.51% examples, 1650110 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:00,976 : INFO : EPOCH 5 - PROGRESS: at 53.07% examples, 1649603 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:01,978 : INFO : EPOCH 5 - PROGRESS: at 58.84% examples, 1649814 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:02,980 : INFO : EPOCH 5 - PROGRESS: at 64.84% examples, 1651926 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:03,987 : INFO : EPOCH 5 - PROGRESS: at 70.11% examples, 1648766 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:04,990 : INFO : EPOCH 5 - PROGRESS: at 75.68% examples, 1648742 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:05,992 : INFO : EPOCH 5 - PROGRESS: at 80.92% examples, 1648392 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:07,000 : INFO : EPOCH 5 - PROGRESS: at 86.24% examples, 1645663 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:08,000 : INFO : EPOCH 5 - PROGRESS: at 92.19% examples, 1646600 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:09,000 : INFO : EPOCH 5 - PROGRESS: at 97.95% examples, 1649197 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:09,304 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:03:09,310 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:03:09,314 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:03:09,318 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:03:09,322 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:03:09,323 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:03:09,324 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:03:09,329 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:03:09,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:03:09,333 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:03:09,333 : INFO : EPOCH - 5 : training on 41519358 raw words (30350580 effective words) took 18.4s, 1651327 effective words/s\n",
      "2022-02-16 10:03:10,343 : INFO : EPOCH 6 - PROGRESS: at 5.38% examples, 1657563 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:11,352 : INFO : EPOCH 6 - PROGRESS: at 10.53% examples, 1676560 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:12,355 : INFO : EPOCH 6 - PROGRESS: at 15.30% examples, 1681923 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:13,360 : INFO : EPOCH 6 - PROGRESS: at 19.85% examples, 1680238 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:14,362 : INFO : EPOCH 6 - PROGRESS: at 24.48% examples, 1680552 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:15,371 : INFO : EPOCH 6 - PROGRESS: at 30.67% examples, 1683200 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:16,373 : INFO : EPOCH 6 - PROGRESS: at 36.69% examples, 1686475 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:17,374 : INFO : EPOCH 6 - PROGRESS: at 42.65% examples, 1683447 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:18,385 : INFO : EPOCH 6 - PROGRESS: at 48.73% examples, 1684384 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:19,388 : INFO : EPOCH 6 - PROGRESS: at 54.27% examples, 1680797 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:20,390 : INFO : EPOCH 6 - PROGRESS: at 59.90% examples, 1674291 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:21,392 : INFO : EPOCH 6 - PROGRESS: at 65.79% examples, 1674755 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:22,396 : INFO : EPOCH 6 - PROGRESS: at 71.27% examples, 1673167 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:23,401 : INFO : EPOCH 6 - PROGRESS: at 76.75% examples, 1670328 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:24,404 : INFO : EPOCH 6 - PROGRESS: at 81.97% examples, 1666213 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:25,404 : INFO : EPOCH 6 - PROGRESS: at 87.64% examples, 1667365 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:26,408 : INFO : EPOCH 6 - PROGRESS: at 93.24% examples, 1664416 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:27,409 : INFO : EPOCH 6 - PROGRESS: at 99.13% examples, 1665995 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:27,513 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:03:27,518 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:03:27,523 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:03:27,529 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:03:27,532 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:03:27,533 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:03:27,536 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:03:27,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:03:27,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:03:27,543 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:03:27,544 : INFO : EPOCH - 6 : training on 41519358 raw words (30349866 effective words) took 18.2s, 1667367 effective words/s\n",
      "2022-02-16 10:03:28,566 : INFO : EPOCH 7 - PROGRESS: at 5.60% examples, 1715715 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:29,576 : INFO : EPOCH 7 - PROGRESS: at 10.71% examples, 1701920 words/s, in_qsize 20, out_qsize 3\n",
      "2022-02-16 10:03:30,579 : INFO : EPOCH 7 - PROGRESS: at 15.44% examples, 1691507 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:31,583 : INFO : EPOCH 7 - PROGRESS: at 19.83% examples, 1677034 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:32,585 : INFO : EPOCH 7 - PROGRESS: at 24.15% examples, 1653590 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:33,600 : INFO : EPOCH 7 - PROGRESS: at 29.80% examples, 1638451 words/s, in_qsize 18, out_qsize 1\n",
      "2022-02-16 10:03:34,601 : INFO : EPOCH 7 - PROGRESS: at 35.46% examples, 1635462 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:35,604 : INFO : EPOCH 7 - PROGRESS: at 41.19% examples, 1630448 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:36,605 : INFO : EPOCH 7 - PROGRESS: at 46.91% examples, 1626693 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:37,606 : INFO : EPOCH 7 - PROGRESS: at 52.23% examples, 1618027 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:38,606 : INFO : EPOCH 7 - PROGRESS: at 57.98% examples, 1624433 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:39,608 : INFO : EPOCH 7 - PROGRESS: at 64.02% examples, 1631090 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:40,611 : INFO : EPOCH 7 - PROGRESS: at 69.33% examples, 1626842 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:41,613 : INFO : EPOCH 7 - PROGRESS: at 74.82% examples, 1626669 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:42,619 : INFO : EPOCH 7 - PROGRESS: at 80.04% examples, 1628044 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:43,623 : INFO : EPOCH 7 - PROGRESS: at 85.35% examples, 1627910 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:44,623 : INFO : EPOCH 7 - PROGRESS: at 91.00% examples, 1625553 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:45,624 : INFO : EPOCH 7 - PROGRESS: at 96.84% examples, 1630181 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:46,124 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:03:46,130 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:03:46,133 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:03:46,136 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:03:46,142 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:03:46,144 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:03:46,145 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:03:46,149 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:03:46,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:03:46,153 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:03:46,153 : INFO : EPOCH - 7 : training on 41519358 raw words (30350473 effective words) took 18.6s, 1632427 effective words/s\n",
      "2022-02-16 10:03:47,161 : INFO : EPOCH 8 - PROGRESS: at 5.40% examples, 1665440 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:48,165 : INFO : EPOCH 8 - PROGRESS: at 10.55% examples, 1685180 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:49,166 : INFO : EPOCH 8 - PROGRESS: at 15.16% examples, 1674388 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:50,169 : INFO : EPOCH 8 - PROGRESS: at 19.71% examples, 1671608 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:51,171 : INFO : EPOCH 8 - PROGRESS: at 24.17% examples, 1659773 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:52,175 : INFO : EPOCH 8 - PROGRESS: at 29.97% examples, 1654579 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:53,175 : INFO : EPOCH 8 - PROGRESS: at 35.91% examples, 1659686 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:54,181 : INFO : EPOCH 8 - PROGRESS: at 42.00% examples, 1660825 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:03:55,187 : INFO : EPOCH 8 - PROGRESS: at 47.79% examples, 1657779 words/s, in_qsize 18, out_qsize 1\n",
      "2022-02-16 10:03:56,188 : INFO : EPOCH 8 - PROGRESS: at 53.39% examples, 1657899 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:57,190 : INFO : EPOCH 8 - PROGRESS: at 59.14% examples, 1656761 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:58,194 : INFO : EPOCH 8 - PROGRESS: at 65.19% examples, 1660331 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:03:59,197 : INFO : EPOCH 8 - PROGRESS: at 70.70% examples, 1661523 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:00,200 : INFO : EPOCH 8 - PROGRESS: at 76.20% examples, 1660305 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:01,209 : INFO : EPOCH 8 - PROGRESS: at 81.65% examples, 1661902 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:02,210 : INFO : EPOCH 8 - PROGRESS: at 87.21% examples, 1661313 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:03,213 : INFO : EPOCH 8 - PROGRESS: at 93.15% examples, 1663957 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:04,216 : INFO : EPOCH 8 - PROGRESS: at 99.02% examples, 1665433 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:04,341 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:04:04,345 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:04:04,349 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:04:04,354 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:04:04,359 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:04:04,360 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:04:04,362 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:04:04,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:04:04,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:04:04,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:04:04,369 : INFO : EPOCH - 8 : training on 41519358 raw words (30346577 effective words) took 18.2s, 1666615 effective words/s\n",
      "2022-02-16 10:04:05,384 : INFO : EPOCH 9 - PROGRESS: at 5.19% examples, 1591248 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:06,386 : INFO : EPOCH 9 - PROGRESS: at 10.19% examples, 1624079 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:07,389 : INFO : EPOCH 9 - PROGRESS: at 14.87% examples, 1637296 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:08,392 : INFO : EPOCH 9 - PROGRESS: at 19.35% examples, 1635085 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:09,398 : INFO : EPOCH 9 - PROGRESS: at 23.88% examples, 1634674 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:10,399 : INFO : EPOCH 9 - PROGRESS: at 29.66% examples, 1637335 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:11,402 : INFO : EPOCH 9 - PROGRESS: at 35.42% examples, 1637893 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:12,403 : INFO : EPOCH 9 - PROGRESS: at 41.27% examples, 1636398 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:13,407 : INFO : EPOCH 9 - PROGRESS: at 47.05% examples, 1634070 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:14,413 : INFO : EPOCH 9 - PROGRESS: at 52.47% examples, 1626657 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:15,418 : INFO : EPOCH 9 - PROGRESS: at 58.15% examples, 1629521 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:16,422 : INFO : EPOCH 9 - PROGRESS: at 64.11% examples, 1633087 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:17,429 : INFO : EPOCH 9 - PROGRESS: at 69.36% examples, 1627574 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:18,431 : INFO : EPOCH 9 - PROGRESS: at 74.82% examples, 1626428 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:19,432 : INFO : EPOCH 9 - PROGRESS: at 79.87% examples, 1624448 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:20,436 : INFO : EPOCH 9 - PROGRESS: at 85.33% examples, 1627685 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:21,440 : INFO : EPOCH 9 - PROGRESS: at 91.30% examples, 1630550 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:22,441 : INFO : EPOCH 9 - PROGRESS: at 97.17% examples, 1635261 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:22,872 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:04:22,880 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:04:22,881 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:04:22,882 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:04:22,891 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:04:22,892 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:04:22,893 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:04:22,895 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:04:22,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:04:22,901 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:04:22,902 : INFO : EPOCH - 9 : training on 41519358 raw words (30350068 effective words) took 18.5s, 1638317 effective words/s\n",
      "2022-02-16 10:04:23,919 : INFO : EPOCH 10 - PROGRESS: at 5.38% examples, 1645456 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:24,926 : INFO : EPOCH 10 - PROGRESS: at 10.38% examples, 1647386 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:25,927 : INFO : EPOCH 10 - PROGRESS: at 15.01% examples, 1649150 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:26,927 : INFO : EPOCH 10 - PROGRESS: at 19.44% examples, 1643176 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:27,928 : INFO : EPOCH 10 - PROGRESS: at 23.95% examples, 1641744 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:28,929 : INFO : EPOCH 10 - PROGRESS: at 29.69% examples, 1639275 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:29,937 : INFO : EPOCH 10 - PROGRESS: at 35.32% examples, 1633416 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:30,940 : INFO : EPOCH 10 - PROGRESS: at 41.22% examples, 1633992 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:31,941 : INFO : EPOCH 10 - PROGRESS: at 47.13% examples, 1636381 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:32,942 : INFO : EPOCH 10 - PROGRESS: at 52.76% examples, 1637529 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:33,944 : INFO : EPOCH 10 - PROGRESS: at 58.32% examples, 1635502 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:34,946 : INFO : EPOCH 10 - PROGRESS: at 64.16% examples, 1635725 words/s, in_qsize 20, out_qsize 0\n",
      "2022-02-16 10:04:35,954 : INFO : EPOCH 10 - PROGRESS: at 69.17% examples, 1623866 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:36,959 : INFO : EPOCH 10 - PROGRESS: at 74.82% examples, 1627170 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:37,966 : INFO : EPOCH 10 - PROGRESS: at 80.16% examples, 1630761 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:38,966 : INFO : EPOCH 10 - PROGRESS: at 85.51% examples, 1631691 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:39,970 : INFO : EPOCH 10 - PROGRESS: at 91.60% examples, 1635976 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:40,976 : INFO : EPOCH 10 - PROGRESS: at 97.46% examples, 1639486 words/s, in_qsize 19, out_qsize 0\n",
      "2022-02-16 10:04:41,363 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-02-16 10:04:41,370 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-02-16 10:04:41,372 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-02-16 10:04:41,373 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-02-16 10:04:41,377 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-02-16 10:04:41,380 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-02-16 10:04:41,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-02-16 10:04:41,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-16 10:04:41,389 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-16 10:04:41,390 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-16 10:04:41,391 : INFO : EPOCH - 10 : training on 41519358 raw words (30350876 effective words) took 18.5s, 1642287 effective words/s\n",
      "2022-02-16 10:04:41,392 : INFO : Word2Vec lifecycle event {'msg': 'training on 415193580 raw words (303496025 effective words) took 184.3s, 1646919 effective words/s', 'datetime': '2022-02-16T10:04:41.392238', 'gensim': '4.1.2', 'python': '3.8.10 (default, Nov 26 2021, 20:14:08) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-94-generic-x86_64-with-glibc2.29', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303496025, 415193580)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(documents, vector_size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at some output \n",
    "This first example shows a simple case of looking up words similar to the word `dirty`. All we need to do here is to call the `most_similar` function and provide the word `dirty` as the positive example. This returns the top 10 similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0573207e-01, -2.2329466e-02, -6.7834030e-03,  1.9804290e-01,\n",
       "        1.4772607e-01, -3.0164273e-02,  2.3066273e-01,  3.6975166e-01,\n",
       "        2.5353116e-01, -1.9336365e-01, -1.6678351e-01, -3.6877635e-01,\n",
       "       -4.5562264e-01,  1.1353964e-01, -2.5317144e-01, -4.4654804e-01,\n",
       "       -2.8384551e-01,  2.4432170e-01,  5.2193022e-01, -4.0197920e-02,\n",
       "        2.7239677e-01, -3.2292494e-01, -1.8172422e-01, -2.1100344e-01,\n",
       "       -1.8505391e-01,  3.0836555e-01,  2.6394278e-01,  1.9174285e-01,\n",
       "        4.6516564e-01,  9.5579758e-02,  3.5293362e-01, -2.4375893e-01,\n",
       "        6.1895269e-01,  4.2461630e-02,  3.3596888e-01, -2.4779865e-01,\n",
       "        1.4510620e-01,  2.0895679e-01, -2.9886974e-02,  1.6037224e-01,\n",
       "        1.0345819e-01,  1.7876672e-02,  9.6555062e-02, -1.0963412e-01,\n",
       "       -1.2511614e-01, -3.1152984e-01,  2.7401239e-01,  7.1831062e-02,\n",
       "        1.0601619e-01,  3.2569060e-01, -2.9800805e-01, -1.6680238e-01,\n",
       "       -2.6191765e-01,  1.9461861e-01, -9.9277914e-02, -2.3037100e-02,\n",
       "        2.9635081e-02,  7.6111913e-02,  2.3381759e-01, -2.1929863e-01,\n",
       "       -7.3582932e-02, -2.4041362e-01,  1.2187660e-01, -6.0988333e-02,\n",
       "       -7.4135393e-02,  6.5186128e-02,  1.4446372e-01,  3.3354245e-02,\n",
       "       -5.1555556e-01, -1.1473644e-01,  9.8697692e-02, -1.2721290e-01,\n",
       "        3.5382929e-01,  6.6141404e-02,  2.6588532e-06, -1.7928952e-01,\n",
       "        1.6893719e-01, -5.2498471e-02, -9.5640756e-02,  7.5170896e-03,\n",
       "        1.4713797e-01, -3.8346335e-01,  2.8530234e-01,  3.1826168e-02,\n",
       "        1.1144289e-01, -2.2427565e-01,  2.3112424e-01, -3.3994704e-01,\n",
       "        8.1042595e-02, -4.1693902e-01,  4.4855168e-01,  1.3926204e-01,\n",
       "       -3.3122059e-02,  3.3557005e-02,  1.7770255e-01, -2.1792994e-01,\n",
       "       -4.0462774e-01,  2.8297096e-01, -2.6189455e-01,  1.0658776e-01,\n",
       "        5.8723114e-02,  6.1194651e-02, -2.1807477e-01,  4.6452913e-01,\n",
       "        1.5574807e-01, -5.1891613e-01, -5.4932839e-01, -3.9233366e-01,\n",
       "       -4.9373847e-01,  3.3170334e-01,  3.9158683e-02,  2.9330659e-01,\n",
       "        3.4962508e-01, -3.5878744e-02,  4.1383587e-02, -6.1811201e-02,\n",
       "       -5.4180022e-02,  3.6889911e-02,  1.2937881e-01,  7.2546033e-03,\n",
       "       -7.9781339e-02,  3.8107401e-01,  4.5700383e-01, -1.3016315e-01,\n",
       "       -7.7759820e-01,  8.4814861e-02, -1.4047176e-01, -3.5537854e-01,\n",
       "        2.8325999e-01,  2.6911185e-03,  1.4853784e-01,  1.6258934e-01,\n",
       "       -2.2002739e-01,  1.0474842e-02, -2.1089944e-01,  9.0744831e-03,\n",
       "       -1.8681258e-01,  4.8915896e-01, -1.8976055e-01, -4.8751328e-02,\n",
       "       -1.4520289e-01, -1.8171379e-01,  3.3299625e-01,  4.8591205e-01,\n",
       "        1.7469695e-01,  1.8901436e-01, -3.9800942e-01,  3.2175112e-01,\n",
       "        3.4179583e-02,  7.4454732e-02], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"niagra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unfriendly', 0.8844205737113953),\n",
       " ('unhelpful', 0.8588504791259766),\n",
       " ('surly', 0.802681028842926),\n",
       " ('unprofessional', 0.798639714717865),\n",
       " ('arrogant', 0.7986181974411011),\n",
       " ('ignorant', 0.7613256573677063),\n",
       " ('impolite', 0.7541064620018005),\n",
       " ('indifferent', 0.7440811395645142),\n",
       " ('abrupt', 0.7424414753913879),\n",
       " ('dismissive', 0.7398391962051392)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w1 = \"rude\"\n",
    "model.wv.most_similar (positive=w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9252454042434692),\n",
       " ('friendly', 0.8340014219284058),\n",
       " ('cordial', 0.8204785585403442),\n",
       " ('professional', 0.7960614562034607),\n",
       " ('attentive', 0.7803134322166443),\n",
       " ('curteous', 0.7787244915962219)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.6701241731643677),\n",
       " ('canada', 0.6491948366165161),\n",
       " ('austria', 0.6285893321037292),\n",
       " ('hawaii', 0.6162881255149841),\n",
       " ('spain', 0.5892347097396851),\n",
       " ('england', 0.5842738747596741)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('astonished', 0.8004058003425598),\n",
       " ('horrified', 0.794355571269989),\n",
       " ('stunned', 0.7809858918190002),\n",
       " ('amazed', 0.7692880034446716),\n",
       " ('dismayed', 0.7443891167640686),\n",
       " ('suprised', 0.723029613494873)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.7213731408119202),\n",
       " ('blanket', 0.7064728140830994),\n",
       " ('quilt', 0.6830916404724121),\n",
       " ('pillowcase', 0.6804502010345459),\n",
       " ('mattress', 0.6799564957618713),\n",
       " ('matress', 0.6795637011528015),\n",
       " ('sheets', 0.6355055570602417),\n",
       " ('foam', 0.6300001740455627),\n",
       " ('pillows', 0.6292189359664917),\n",
       " ('quilts', 0.6161453127861023)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75410646"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"rude\",w2=\"impolite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2607754"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `vector_size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
